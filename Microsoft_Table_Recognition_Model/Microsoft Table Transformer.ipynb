{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-markdown",
   "metadata": {},
   "source": [
    "# Weave Pattern Rectangle Detection\n",
    "## Using Microsoft Table Transformer for Textile Pattern Analysis\n",
    "\n",
    "**Model:** microsoft/table-transformer-structure-recognition  \n",
    "**Purpose:** Detect and count rectangular elements in weave pattern images  \n",
    "**GPU:** Optimized for NVIDIA Blackwell  \n",
    "**Status:** Production-ready (no training required)\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Start\n",
    "1. Run cells 1-4 to set up environment\n",
    "2. Update image paths in Cell 5\n",
    "3. Run Cell 6 to detect rectangles\n",
    "4. Run Cell 7 to visualize results\n",
    "5. Run Cell 8 to register model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a17b7a-afb4-4b3c-9e7c-eb3fb1b17522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUDA COMPATIBILITY CONFIGURATION\n",
      "============================================================\n",
      "✓ CUDA environment variables configured\n",
      "✓ Warning filters applied\n",
      "\n",
      "IMPORTANT: Do not skip this cell or move it!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1: CUDA COMPATIBILITY CONFIGURATION\n",
    "# Critical: Run this cell FIRST before any other imports\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUDA COMPATIBILITY CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Critical: Set CUDA environment variables BEFORE importing torch\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Synchronous CUDA operations\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'  # Memory management\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '0'  # Disable device-side assertions\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"✓ CUDA environment variables configured\")\n",
    "print(\"✓ Warning filters applied\")\n",
    "print(\"\\nIMPORTANT: Do not skip this cell or move it!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "install-dependencies",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INSTALLING CUDA-COMPATIBLE PYTORCH\n",
      "============================================================\n",
      "\n",
      "1. Removing old PyTorch installations...\n",
      "\n",
      "2. Installing PyTorch with CUDA 12.8 support...\n",
      "   (This takes 2-3 minutes - downloading ~900MB)\n",
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu128\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251112%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/torchvision-0.25.0.dev20251112%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/torchaudio-2.10.0.dev20251112%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pytorch-triton==3.5.1+gitbfeb0668 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.5.1%2Bgitbfeb0668-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.5.1%2Bgitbfeb0668-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/torchvision-0.25.0.dev20251112%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251111%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (918.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m918.4/918.4 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu128/torchaudio-2.10.0.dev20251112%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, sympy, pytorch-triton, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "Successfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 pytorch-triton-3.5.1+gitbfeb0668 sympy-1.14.0 torch-2.10.0.dev20251111+cu128 torchaudio-2.10.0.dev20251112+cu128 torchvision-0.25.0.dev20251112+cu128\n",
      "\n",
      "✓ PyTorch installation complete\n",
      "\n",
      "3. Installing Hugging Face Transformers and tools...\n",
      "\n",
      "✓ All dependencies installed\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: INSTALL PYTORCH WITH CUDA 12.8 SUPPORT\n",
    "# Critical: Blackwell GPUs require CUDA 12.8+ and PyTorch nightly\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLING CUDA-COMPATIBLE PYTORCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uninstall existing PyTorch versions\n",
    "print(\"\\n1. Removing old PyTorch installations...\")\n",
    "!pip uninstall torch torchvision torchaudio -y -q\n",
    "\n",
    "# Install PyTorch nightly with CUDA 12.8 (supports Blackwell sm_120)\n",
    "print(\"\\n2. Installing PyTorch with CUDA 12.8 support...\")\n",
    "print(\"   (This takes 2-3 minutes - downloading ~900MB)\")\n",
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "\n",
    "print(\"\\n✓ PyTorch installation complete\")\n",
    "\n",
    "# Install other dependencies\n",
    "print(\"\\n3. Installing Hugging Face Transformers and tools...\")\n",
    "!pip install -q transformers accelerate pillow matplotlib timm\n",
    "\n",
    "print(\"\\n✓ All dependencies installed\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "IMPORTING LIBRARIES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 01:02:01.753370: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-14 01:02:01.771117: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763082121.791780     820 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763082121.798734     820 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-14 01:02:01.822635: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Using device: cuda\n",
      "✓ GPU optimizations configured\n",
      "✓ All libraries imported successfully\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3: IMPORT LIBRARIES\n",
    "# Import all required packages\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPORTING LIBRARIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, TableTransformerForObjectDetection\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n✓ Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Configure for Blackwell GPU\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False\n",
    "    torch.backends.cudnn.allow_tf32 = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✓ GPU optimizations configured\")\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING TABLE TRANSFORMER MODEL\n",
      "============================================================\n",
      "\n",
      "Loading model: microsoft/table-transformer-structure-recognition\n",
      "This may take 2-3 minutes on first run (downloading ~300MB)...\n",
      "\n",
      "✓ Image processor loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded and moved to GPU\n",
      "\n",
      "Model Information:\n",
      "  • Classes detected: 6\n",
      "  • Detection classes: ['table', 'table column', 'table row', 'table column header', 'table projected row header', 'table spanning cell']\n",
      "  • Parameters: 28.8M\n",
      "  • GPU memory allocated: 0.11 GB\n",
      "\n",
      "✓ Model ready for inference\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 4: LOAD TABLE TRANSFORMER MODEL\n",
    "# Downloads and initializes microsoft/table-transformer-structure-recognition\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING TABLE TRANSFORMER MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "MODEL_NAME = \"microsoft/table-transformer-structure-recognition\"\n",
    "\n",
    "print(f\"\\nLoading model: {MODEL_NAME}\")\n",
    "print(\"This may take 2-3 minutes on first run (downloading ~300MB)...\\n\")\n",
    "\n",
    "try:\n",
    "    # Load image processor\n",
    "    processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "    print(\"✓ Image processor loaded\")\n",
    "    \n",
    "    # Load model\n",
    "    model = TableTransformerForObjectDetection.from_pretrained(MODEL_NAME)\n",
    "    model.to(device)\n",
    "    model.eval()  # Set to inference mode\n",
    "    print(\"✓ Model loaded and moved to GPU\")\n",
    "    \n",
    "    # Display model info\n",
    "    print(f\"\\nModel Information:\")\n",
    "    print(f\"  • Classes detected: {len(model.config.id2label)}\")\n",
    "    print(f\"  • Detection classes: {list(model.config.id2label.values())}\")\n",
    "    print(f\"  • Parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "    \n",
    "    # Memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        print(f\"  • GPU memory allocated: {allocated:.2f} GB\")\n",
    "    \n",
    "    print(\"\\n✓ Model ready for inference\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading model: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Check internet connection\")\n",
    "    print(\"  2. Verify Hugging Face access\")\n",
    "    print(\"  3. Clear cache: rm -rf ~/.cache/huggingface\")\n",
    "    raise\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detection-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEFINING DETECTION FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "✓ Detection functions defined:\n",
      "  • detect_rectangles() - Single image detection\n",
      "  • batch_detect_rectangles() - Multiple image processing\n",
      "  • print_detection_summary() - Result formatting\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5: RECTANGLE DETECTION FUNCTIONS\n",
    "# Core functions for detecting and counting rectangles\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEFINING DETECTION FUNCTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def detect_rectangles(image_path, confidence_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Detect rectangular elements in weave pattern images.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to weave pattern image\n",
    "        confidence_threshold: Minimum confidence score (0-1)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with detection results and statistics\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_size = image.size\n",
    "    \n",
    "    # Prepare input\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Post-process results\n",
    "    target_sizes = torch.tensor([image.size[::-1]]).to(device)\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs,\n",
    "        threshold=confidence_threshold,\n",
    "        target_sizes=target_sizes\n",
    "    )[0]\n",
    "    \n",
    "    # Extract detections\n",
    "    detections = []\n",
    "    rectangle_counts = {}\n",
    "    \n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        label_name = model.config.id2label[label.item()]\n",
    "        confidence = round(score.item(), 3)\n",
    "        box_coords = [round(i, 2) for i in box.tolist()]\n",
    "        \n",
    "        # Calculate box area and dimensions\n",
    "        width = box_coords[2] - box_coords[0]\n",
    "        height = box_coords[3] - box_coords[1]\n",
    "        area = width * height\n",
    "        \n",
    "        detection = {\n",
    "            'class': label_name,\n",
    "            'confidence': confidence,\n",
    "            'box': box_coords,  # [x_min, y_min, x_max, y_max]\n",
    "            'center': [round((box_coords[0] + box_coords[2])/2, 2),\n",
    "                      round((box_coords[1] + box_coords[3])/2, 2)],\n",
    "            'dimensions': {'width': round(width, 2), 'height': round(height, 2)},\n",
    "            'area': round(area, 2)\n",
    "        }\n",
    "        \n",
    "        detections.append(detection)\n",
    "        rectangle_counts[label_name] = rectangle_counts.get(label_name, 0) + 1\n",
    "    \n",
    "    return {\n",
    "        'image_path': str(image_path),\n",
    "        'image_size': original_size,\n",
    "        'total_rectangles': len(detections),\n",
    "        'counts_by_type': rectangle_counts,\n",
    "        'detections': detections,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'confidence_threshold': confidence_threshold\n",
    "    }\n",
    "\n",
    "\n",
    "def batch_detect_rectangles(image_paths, confidence_threshold=0.1, batch_size=4):\n",
    "    \"\"\"\n",
    "    Process multiple weave pattern images efficiently.\n",
    "    \n",
    "    Args:\n",
    "        image_paths: List of image paths\n",
    "        confidence_threshold: Minimum confidence score\n",
    "        batch_size: Number of images to process simultaneously\n",
    "    \n",
    "    Returns:\n",
    "        List of detection results for each image\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        \n",
    "        for path in batch_paths:\n",
    "            try:\n",
    "                result = detect_rectangles(path, confidence_threshold)\n",
    "                all_results.append(result)\n",
    "                print(f\"✓ Processed: {Path(path).name} - {result['total_rectangles']} rectangles\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing {path}: {e}\")\n",
    "                all_results.append({'error': str(e), 'image_path': str(path)})\n",
    "        \n",
    "        # Clear GPU cache between batches\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def print_detection_summary(results):\n",
    "    \"\"\"\n",
    "    Print a formatted summary of detection results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETECTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nImage: {Path(results['image_path']).name}\")\n",
    "    print(f\"Image size: {results['image_size'][0]}x{results['image_size'][1]}\")\n",
    "    print(f\"Confidence threshold: {results['confidence_threshold']}\")\n",
    "    print(f\"\\nTotal rectangles detected: {results['total_rectangles']}\")\n",
    "    \n",
    "    if results['counts_by_type']:\n",
    "        print(\"\\nBreakdown by type:\")\n",
    "        for rect_type, count in results['counts_by_type'].items():\n",
    "            print(f\"  • {rect_type}: {count}\")\n",
    "    \n",
    "    print(\"\\nTop 5 detections:\")\n",
    "    for i, det in enumerate(results['detections'][:5], 1):\n",
    "        print(f\"  {i}. {det['class']} (confidence: {det['confidence']})\")\n",
    "        print(f\"     Box: {det['box']}\")\n",
    "        print(f\"     Dimensions: {det['dimensions']['width']}x{det['dimensions']['height']} px\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "print(\"\\n✓ Detection functions defined:\")\n",
    "print(\"  • detect_rectangles() - Single image detection\")\n",
    "print(\"  • batch_detect_rectangles() - Multiple image processing\")\n",
    "print(\"  • print_detection_summary() - Result formatting\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "visualization-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEFINING VISUALIZATION FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "✓ Visualization functions defined:\n",
      "  • draw_detections() - Annotate single image\n",
      "  • visualize_detection_grid() - Display multiple results\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6: VISUALIZATION FUNCTIONS\n",
    "# Draw bounding boxes and create visual outputs\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEFINING VISUALIZATION FUNCTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def draw_detections(image_path, results, output_path=None, show_confidence=True):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on image with labels.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to original image\n",
    "        results: Detection results from detect_rectangles()\n",
    "        output_path: Where to save annotated image (optional)\n",
    "        show_confidence: Whether to display confidence scores\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image with annotations\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Define colors for different classes\n",
    "    colors = {\n",
    "        'table': 'red',\n",
    "        'table column': 'blue',\n",
    "        'table row': 'green',\n",
    "        'table column header': 'purple',\n",
    "        'table projected row header': 'orange',\n",
    "        'table spanning cell': 'cyan',\n",
    "        'no object': 'gray'\n",
    "    }\n",
    "    \n",
    "    # Draw each detection\n",
    "    for det in results['detections']:\n",
    "        box = det['box']\n",
    "        class_name = det['class']\n",
    "        confidence = det['confidence']\n",
    "        \n",
    "        # Get color\n",
    "        color = colors.get(class_name, 'yellow')\n",
    "        \n",
    "        # Draw bounding box\n",
    "        draw.rectangle(box, outline=color, width=3)\n",
    "        \n",
    "        # Draw label\n",
    "        label = f\"{class_name}\"\n",
    "        if show_confidence:\n",
    "            label += f\" {confidence:.2f}\"\n",
    "        \n",
    "        # Text background\n",
    "        text_bbox = draw.textbbox((box[0], box[1]-20), label)\n",
    "        draw.rectangle(text_bbox, fill=color)\n",
    "        draw.text((box[0], box[1]-20), label, fill='white')\n",
    "    \n",
    "    # Add summary text\n",
    "    summary = f\"Total rectangles: {results['total_rectangles']}\"\n",
    "    draw.text((10, 10), summary, fill='white', stroke_width=2, stroke_fill='black')\n",
    "    \n",
    "    # Save if output path provided\n",
    "    if output_path:\n",
    "        image.save(output_path)\n",
    "        print(f\"\\n✓ Annotated image saved: {output_path}\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize_detection_grid(results_list, figsize=(15, 10), max_images=6):\n",
    "    \"\"\"\n",
    "    Create a grid visualization of multiple detection results.\n",
    "    \n",
    "    Args:\n",
    "        results_list: List of detection results from batch processing\n",
    "        figsize: Figure size for matplotlib\n",
    "        max_images: Maximum images to display\n",
    "    \"\"\"\n",
    "    n_images = min(len(results_list), max_images)\n",
    "    cols = 3\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, results in enumerate(results_list[:max_images]):\n",
    "        if 'error' in results:\n",
    "            continue\n",
    "            \n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Draw image with detections\n",
    "        annotated = draw_detections(results['image_path'], results, output_path=None, show_confidence=False)\n",
    "        \n",
    "        ax.imshow(annotated)\n",
    "        ax.set_title(f\"{Path(results['image_path']).name}\\n{results['total_rectangles']} rectangles\", \n",
    "                    fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_images, rows * cols):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n✓ Visualization functions defined:\")\n",
    "print(\"  • draw_detections() - Annotate single image\")\n",
    "print(\"  • visualize_detection_grid() - Display multiple results\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "run-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECTANGLE DETECTION\n",
      "============================================================\n",
      "\n",
      "Mode: SINGLE\n",
      "Confidence threshold: 0.6\n",
      "Output directory: detection_results\n",
      "\n",
      "Processing: test_26_30.png...\n",
      "\n",
      "\n",
      "============================================================\n",
      "DETECTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Image: test_26_30.png\n",
      "Image size: 480x555\n",
      "Confidence threshold: 0.6\n",
      "\n",
      "Total rectangles detected: 5\n",
      "\n",
      "Breakdown by type:\n",
      "  • table column: 2\n",
      "  • table row: 2\n",
      "  • table: 1\n",
      "\n",
      "Top 5 detections:\n",
      "  1. table column (confidence: 0.681)\n",
      "     Box: [41.54, 37.72, 101.27, 519.4]\n",
      "     Dimensions: 59.73x481.68 px\n",
      "  2. table row (confidence: 0.611)\n",
      "     Box: [44.87, 55.02, 419.0, 84.82]\n",
      "     Dimensions: 374.13x29.8 px\n",
      "  3. table column (confidence: 0.697)\n",
      "     Box: [359.95, 39.05, 416.33, 519.61]\n",
      "     Dimensions: 56.38x480.56 px\n",
      "  4. table row (confidence: 0.695)\n",
      "     Box: [43.33, 35.83, 418.4, 56.44]\n",
      "     Dimensions: 375.07x20.61 px\n",
      "  5. table (confidence: 0.839)\n",
      "     Box: [43.8, 40.45, 416.98, 519.09]\n",
      "     Dimensions: 373.18x478.64 px\n",
      "============================================================\n",
      "\n",
      "✓ Results saved: detection_results/detection_results.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'draw_detections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Visualize\u001b[39;00m\n\u001b[1;32m     49\u001b[0m output_image \u001b[38;5;241m=\u001b[39m OUTPUT_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotated_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(SINGLE_IMAGE_PATH)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m annotated \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_detections\u001b[49m(SINGLE_IMAGE_PATH, results, output_path\u001b[38;5;241m=\u001b[39moutput_image)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Display\u001b[39;00m\n\u001b[1;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'draw_detections' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7: RUN DETECTION ON YOUR IMAGES\n",
    "# UPDATE THE IMAGE PATHS BELOW WITH YOUR WEAVE PATTERN IMAGES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECTANGLE DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ⚠️ UPDATE THESE PATHS TO YOUR WEAVE PATTERN IMAGES\n",
    "# Examples:\n",
    "# - Single image: \"./weave_patterns/pattern1.jpg\"\n",
    "# - Multiple images: [\"./pattern1.jpg\", \"./pattern2.jpg\", \"./pattern3.jpg\"]\n",
    "\n",
    "# Option 1: Single image detection\n",
    "SINGLE_IMAGE_PATH = \"test_26_30.png\"  # ⚠️ CHANGE THIS\n",
    "\n",
    "# Option 2: Batch processing (multiple images)\n",
    "IMAGE_FOLDER = Path(\"./weave_patterns\")  # ⚠️ CHANGE THIS\n",
    "BATCH_IMAGES = list(IMAGE_FOLDER.glob(\"*.jpg\")) + list(IMAGE_FOLDER.glob(\"*.png\"))\n",
    "\n",
    "# Detection parameters\n",
    "CONFIDENCE_THRESHOLD = 0.6  # Adjust between 0.3-0.9 (lower = more detections)\n",
    "OUTPUT_DIR = Path(\"./detection_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Choose mode: 'single' or 'batch'\n",
    "MODE = 'single'  # Change to 'batch' for multiple images\n",
    "\n",
    "print(f\"\\nMode: {MODE.upper()}\")\n",
    "print(f\"Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "if MODE == 'single':\n",
    "    # Single image detection\n",
    "    if Path(SINGLE_IMAGE_PATH).exists():\n",
    "        print(f\"Processing: {SINGLE_IMAGE_PATH}...\\n\")\n",
    "        \n",
    "        results = detect_rectangles(SINGLE_IMAGE_PATH, CONFIDENCE_THRESHOLD)\n",
    "        print_detection_summary(results)\n",
    "        \n",
    "        # Save results\n",
    "        output_json = OUTPUT_DIR / \"detection_results.json\"\n",
    "        with open(output_json, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"\\n✓ Results saved: {output_json}\")\n",
    "        \n",
    "        # Visualize\n",
    "        output_image = OUTPUT_DIR / f\"annotated_{Path(SINGLE_IMAGE_PATH).name}\"\n",
    "        annotated = draw_detections(SINGLE_IMAGE_PATH, results, output_path=output_image)\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(annotated)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Detected {results['total_rectangles']} rectangles\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(f\"❌ Image not found: {SINGLE_IMAGE_PATH}\")\n",
    "        print(\"\\nPlease update SINGLE_IMAGE_PATH with your image path.\")\n",
    "\n",
    "elif MODE == 'batch':\n",
    "    # Batch processing\n",
    "    if BATCH_IMAGES:\n",
    "        print(f\"Processing {len(BATCH_IMAGES)} images...\\n\")\n",
    "        \n",
    "        batch_results = batch_detect_rectangles(BATCH_IMAGES, CONFIDENCE_THRESHOLD)\n",
    "        \n",
    "        # Save batch results\n",
    "        output_json = OUTPUT_DIR / \"batch_detection_results.json\"\n",
    "        with open(output_json, 'w') as f:\n",
    "            json.dump(batch_results, f, indent=2)\n",
    "        print(f\"\\n✓ Batch results saved: {output_json}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_rectangles = sum(r.get('total_rectangles', 0) for r in batch_results if 'error' not in r)\n",
    "        successful = sum(1 for r in batch_results if 'error' not in r)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BATCH PROCESSING SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total images: {len(BATCH_IMAGES)}\")\n",
    "        print(f\"Successful: {successful}\")\n",
    "        print(f\"Failed: {len(BATCH_IMAGES) - successful}\")\n",
    "        print(f\"Total rectangles detected: {total_rectangles}\")\n",
    "        print(f\"Average per image: {total_rectangles/successful:.1f}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Visualize grid\n",
    "        visualize_detection_grid(batch_results)\n",
    "        \n",
    "    else:\n",
    "        print(f\"❌ No images found in: {IMAGE_FOLDER}\")\n",
    "        print(\"\\nPlease update IMAGE_FOLDER with your image directory.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Invalid MODE. Use 'single' or 'batch'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "export-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPORTING DETECTION DATA\n",
      "============================================================\n",
      "✓ Exported 5 detections to: detection_results/detections.csv\n",
      "\n",
      "Preview:\n",
      "            image         class  confidence   x_min  y_min   x_max   y_max  \\\n",
      "0  test_26_30.png  table column       0.681   41.54  37.72  101.27  519.40   \n",
      "1  test_26_30.png     table row       0.611   44.87  55.02  419.00   84.82   \n",
      "2  test_26_30.png  table column       0.697  359.95  39.05  416.33  519.61   \n",
      "3  test_26_30.png     table row       0.695   43.33  35.83  418.40   56.44   \n",
      "4  test_26_30.png         table       0.839   43.80  40.45  416.98  519.09   \n",
      "\n",
      "   center_x  center_y   width  height       area  \n",
      "0     71.41    278.56   59.73  481.68   28770.75  \n",
      "1    231.94     69.92  374.13   29.80   11149.07  \n",
      "2    388.14    279.33   56.38  480.56   27093.97  \n",
      "3    230.86     46.13  375.07   20.61    7730.19  \n",
      "4    230.39    279.77  373.18  478.64  178618.88  \n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 8: EXPORT DETECTION DATA\n",
    "# Export results to CSV for analysis\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPORTING DETECTION DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def export_to_csv(results, output_path):\n",
    "    \"\"\"\n",
    "    Export detection results to CSV format.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    if isinstance(results, dict) and 'detections' in results:\n",
    "        # Single image results\n",
    "        results = [results]\n",
    "    \n",
    "    for result in results:\n",
    "        if 'error' in result:\n",
    "            continue\n",
    "            \n",
    "        for det in result['detections']:\n",
    "            rows.append({\n",
    "                'image': Path(result['image_path']).name,\n",
    "                'class': det['class'],\n",
    "                'confidence': det['confidence'],\n",
    "                'x_min': det['box'][0],\n",
    "                'y_min': det['box'][1],\n",
    "                'x_max': det['box'][2],\n",
    "                'y_max': det['box'][3],\n",
    "                'center_x': det['center'][0],\n",
    "                'center_y': det['center'][1],\n",
    "                'width': det['dimensions']['width'],\n",
    "                'height': det['dimensions']['height'],\n",
    "                'area': det['area']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Exported {len(df)} detections to: {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Export current results\n",
    "try:\n",
    "    if MODE == 'single' and 'results' in locals():\n",
    "        csv_path = OUTPUT_DIR / \"detections.csv\"\n",
    "        df = export_to_csv(results, csv_path)\n",
    "        \n",
    "        print(\"\\nPreview:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    elif MODE == 'batch' and 'batch_results' in locals():\n",
    "        csv_path = OUTPUT_DIR / \"batch_detections.csv\"\n",
    "        df = export_to_csv(batch_results, csv_path)\n",
    "        \n",
    "        print(\"\\nStatistics:\")\n",
    "        print(df.groupby('class').agg({\n",
    "            'confidence': ['mean', 'min', 'max'],\n",
    "            'area': ['mean', 'min', 'max'],\n",
    "            'image': 'count'\n",
    "        }).round(2))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Export failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mlflow-registration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MLFLOW MODEL REGISTRATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/14 01:31:04 INFO mlflow.tracking.fluent: Experiment with name 'weave-pattern-detection' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registering model: weave-pattern-rectangle-detector\n",
      "Experiment: weave-pattern-detection\n",
      "Tracking URI: ./mlruns\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/14 01:31:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.10.0.dev20251113+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.10.0.dev20251113' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/11/14 01:31:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'weave-pattern-rectangle-detector'.\n",
      "Created version '1' of model 'weave-pattern-rectangle-detector'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model registered successfully\n",
      "✓ Run ID: 70035c24d85c483caa1eb3bb639860c3\n",
      "✓ Model URI: runs:/70035c24d85c483caa1eb3bb639860c3/model\n",
      "\n",
      "============================================================\n",
      "DEPLOYMENT INSTRUCTIONS\n",
      "============================================================\n",
      "\n",
      "1. Open HP AI Studio\n",
      "2. Navigate to 'Deployments' tab\n",
      "3. Find model: 'weave-pattern-rectangle-detector'\n",
      "4. Click 'Deploy' to create endpoint\n",
      "\n",
      "Model will be available for API inference!\n",
      "============================================================\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 9: MLFLOW MODEL REGISTRATION\n",
    "# Register model for deployment in HP AI Studio\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MLFLOW MODEL REGISTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME_MLFLOW = \"weave-pattern-rectangle-detector\"\n",
    "MODEL_VERSION = \"1.0.0\"\n",
    "MLFLOW_TRACKING_URI = \"./mlruns\"\n",
    "EXPERIMENT_NAME = \"weave-pattern-detection\"\n",
    "\n",
    "print(f\"\\nRegistering model: {MODEL_NAME_MLFLOW}\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Tracking URI: {MLFLOW_TRACKING_URI}\\n\")\n",
    "\n",
    "try:\n",
    "    # Set MLflow tracking\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    \n",
    "    # Start run\n",
    "    with mlflow.start_run(run_name=f\"{MODEL_NAME_MLFLOW}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\") as run:\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "        mlflow.log_param(\"model_version\", MODEL_VERSION)\n",
    "        mlflow.log_param(\"confidence_threshold\", CONFIDENCE_THRESHOLD)\n",
    "        mlflow.log_param(\"device\", str(device))\n",
    "        \n",
    "        # Log model info\n",
    "        num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "        mlflow.log_param(\"parameters_millions\", round(num_params, 2))\n",
    "        mlflow.log_param(\"classes\", len(model.config.id2label))\n",
    "        \n",
    "        # Log detection statistics if available\n",
    "        if 'results' in locals():\n",
    "            mlflow.log_metric(\"rectangles_detected\", results['total_rectangles'])\n",
    "        elif 'batch_results' in locals():\n",
    "            total = sum(r.get('total_rectangles', 0) for r in batch_results if 'error' not in r)\n",
    "            mlflow.log_metric(\"total_rectangles_detected\", total)\n",
    "        \n",
    "        # Log PyTorch model\n",
    "        mlflow.pytorch.log_model(\n",
    "            pytorch_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=MODEL_NAME_MLFLOW\n",
    "        )\n",
    "        \n",
    "        # Log processor config\n",
    "        processor_config = {\n",
    "            'model_name': MODEL_NAME,\n",
    "            'image_size': processor.size,\n",
    "            'do_normalize': processor.do_normalize,\n",
    "            'do_resize': processor.do_resize\n",
    "        }\n",
    "        mlflow.log_dict(processor_config, \"processor_config.json\")\n",
    "        \n",
    "        # Log artifacts\n",
    "        if OUTPUT_DIR.exists():\n",
    "            mlflow.log_artifacts(str(OUTPUT_DIR), \"detection_results\")\n",
    "        \n",
    "        print(f\"\\n✓ Model registered successfully\")\n",
    "        print(f\"✓ Run ID: {run.info.run_id}\")\n",
    "        print(f\"✓ Model URI: runs:/{run.info.run_id}/model\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DEPLOYMENT INSTRUCTIONS\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\n1. Open HP AI Studio\")\n",
    "        print(\"2. Navigate to 'Deployments' tab\")\n",
    "        print(f\"3. Find model: '{MODEL_NAME_MLFLOW}'\")\n",
    "        print(\"4. Click 'Deploy' to create endpoint\")\n",
    "        print(\"\\nModel will be available for API inference!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Registration failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Ensure MLflow is installed: pip install mlflow\")\n",
    "    print(\"  2. Check write permissions for mlruns directory\")\n",
    "    print(\"  3. Verify model and processor are loaded\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inference-api",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRODUCTION INFERENCE API\n",
      "============================================================\n",
      "\n",
      "✓ Production detector initialized\n",
      "\n",
      "Usage:\n",
      "  results = detector.detect('image.jpg')\n",
      "  batch_results = detector.detect_batch(image_list)\n",
      "  stats = detector.get_statistics(results)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 10: PRODUCTION INFERENCE API\n",
    "# Complete API for production deployment\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRODUCTION INFERENCE API\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class WeavePatternDetector:\n",
    "    \"\"\"\n",
    "    Production-ready API for weave pattern rectangle detection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, processor, device, confidence_threshold=0.6):\n",
    "        self.model = model\n",
    "        self.processor = processor\n",
    "        self.device = device\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.model.eval()\n",
    "    \n",
    "    def detect(self, image_path):\n",
    "        \"\"\"\n",
    "        Detect rectangles in weave pattern image.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to image file or PIL Image\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with detection results\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        if isinstance(image_path, str):\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        else:\n",
    "            image = image_path\n",
    "        \n",
    "        # Prepare input\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Post-process\n",
    "        target_sizes = torch.tensor([image.size[::-1]]).to(self.device)\n",
    "        results = self.processor.post_process_object_detection(\n",
    "            outputs,\n",
    "            threshold=self.confidence_threshold,\n",
    "            target_sizes=target_sizes\n",
    "        )[0]\n",
    "        \n",
    "        # Format output\n",
    "        detections = []\n",
    "        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "            detections.append({\n",
    "                'class': self.model.config.id2label[label.item()],\n",
    "                'confidence': float(score.item()),\n",
    "                'box': [float(x) for x in box.tolist()]\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'total_rectangles': len(detections),\n",
    "            'detections': detections,\n",
    "            'image_size': image.size,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def detect_batch(self, image_paths, batch_size=4):\n",
    "        \"\"\"\n",
    "        Process multiple images.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for path in image_paths:\n",
    "            results.append(self.detect(path))\n",
    "        return results\n",
    "    \n",
    "    def get_statistics(self, results):\n",
    "        \"\"\"\n",
    "        Calculate statistics from detection results.\n",
    "        \"\"\"\n",
    "        if isinstance(results, dict):\n",
    "            results = [results]\n",
    "        \n",
    "        total_rectangles = sum(r['total_rectangles'] for r in results)\n",
    "        avg_confidence = sum(\n",
    "            sum(d['confidence'] for d in r['detections']) / max(r['total_rectangles'], 1)\n",
    "            for r in results\n",
    "        ) / len(results)\n",
    "        \n",
    "        return {\n",
    "            'total_images': len(results),\n",
    "            'total_rectangles': total_rectangles,\n",
    "            'avg_rectangles_per_image': total_rectangles / len(results),\n",
    "            'avg_confidence': avg_confidence\n",
    "        }\n",
    "\n",
    "# Initialize production detector\n",
    "detector = WeavePatternDetector(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    device=device,\n",
    "    confidence_threshold=CONFIDENCE_THRESHOLD\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Production detector initialized\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  results = detector.detect('image.jpg')\")\n",
    "print(\"  batch_results = detector.detect_batch(image_list)\")\n",
    "print(\"  stats = detector.get_statistics(results)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-notes",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 Deployment Complete!\n",
    "\n",
    "### What you've accomplished:\n",
    "\n",
    "✅ Loaded Microsoft Table Transformer model  \n",
    "✅ Created rectangle detection pipeline  \n",
    "✅ Implemented batch processing  \n",
    "✅ Built visualization tools  \n",
    "✅ Exported data to CSV  \n",
    "✅ Registered model with MLflow  \n",
    "✅ Created production-ready API  \n",
    "\n",
    "### Next steps:\n",
    "\n",
    "1. **Test with your weave patterns** - Update image paths in Cell 7\n",
    "2. **Adjust confidence threshold** - Lower = more detections, Higher = fewer false positives\n",
    "3. **Deploy to HP AI Studio** - Follow instructions in Cell 9\n",
    "4. **Integrate into your workflow** - Use the `WeavePatternDetector` class from Cell 10\n",
    "\n",
    "### Performance tips:\n",
    "\n",
    "- **GPU Memory:** Model uses ~6-8GB VRAM\n",
    "- **Inference Speed:** 30-80ms per image on Blackwell GPU\n",
    "- **Batch Size:** Use 4-8 for optimal throughput\n",
    "- **Clear Cache:** Run `torch.cuda.empty_cache()` between large batches\n",
    "\n",
    "### Troubleshooting:\n",
    "\n",
    "- **Too many false positives?** Increase `CONFIDENCE_THRESHOLD` (try 0.7-0.8)\n",
    "- **Missing rectangles?** Decrease threshold (try 0.4-0.5)\n",
    "- **Out of memory?** Reduce batch size or clear cache more frequently\n",
    "- **Slow inference?** Ensure model is on GPU: `model.to('cuda')`\n",
    "\n",
    "---\n",
    "\n",
    "**Model:** microsoft/table-transformer-structure-recognition  \n",
    "**License:** Apache 2.0  \n",
    "**GPU:** NVIDIA Blackwell optimized  \n",
    "**Framework:** PyTorch + Transformers  \n",
    "\n",
    "Good luck with your weave pattern analysis! 🧵📐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
